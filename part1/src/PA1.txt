            +--------------------+
            |        CS 140      |
            | PROJECT 1: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Yuze Xia <yuzexia@buffalo.edu>
Zhexi Chen <zchen65@buffao.edu>
Christopher Potts <cepotts@buffalo.edu>


---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

1. static struct list block_list： a list that stores threads that are sleeping (being blocked).
     And after every tick, we could check if any thread inside the block_list
    wants to wake up (being unblock)

2. int64_t sleepticks: a new struct memeber of struct thread, 
    used to record at what ticks a thread needs to wake up.

3. struct semaphore sem: a new struct member of struct thread, used to block and unblock thread

4. enum intr_level old_level: an enumeration used to breifly turn the interrupt off and turn it on after.

5. struct list_elem block_elem, a new struct member of struct thread, 
    used as list element for block_list list


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

When timer_sleep() is called, timer_sleepp(ticks) is executed and jump to thread.c
because needs to access block_list. In timer_sleepp(int64_t tick), first get the current system ticks
by calling timer_ticks (), set sleepticks for the current thread, push it into block_list and block it.
The purpose of the timer interrupt handler is to increase number of timer ticks since OS booted by 1 
and call thread_tick(). In thread_tick() function, new function loop_to_check is called to check if 
any thread in block_list is ready to wake up at current tick.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
Since we are using the block_list to store all blocked threads, there is 
no need for timer interrupt handler to spend time on checking on all threads.


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

When calling timer_sleep(), we need to block the current thread and set at what time it needs to wake up.
To prevent race condition, the enum intr_level is used, so that we could turn off the interrupt briefly. while interrupts are off,
there is no concurrency, so there’s no possibility for race conditions. And we turn the interrupt on when each 
thread finish with timer_sleep() call.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
while interrupts are off, there is no concurrency, so there’s no possibility for a timer interrupt to work, so there 
will not have race conditions .

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
This design is straight-forward and easy to debug because it involves less steps than another design I considered
I had another design is to check all the threads from highest priority to lowest priority, and wake up the first thread
that has a status of THREAD_BLOCKED, but it is not efficient and might cause unexpected bug.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

1. struct list donators, a new struct memeber in struct thread, used to store
the threads who are waiting for the locks held by current thread, but, for each lock, only store 
the one with highest priority. 

2. struct list_elem donator_elem: a new struct memeber in struct thread，it is
used as list element for donators list.

3. struct lock * waiting_lock: a new struct memeber in struct thread, it is used to
    record which lock this thread is waiting for.

4. int ini_priority:a new struct memeber in struct thread, it is used to record the
    initial priority of a thread, so that the thread can sill get its original priority
    back even if it is donated with other priorities

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)
My program assign a list named donators to every thread to keep track priority donation 


┌────────────┐            ┌─────────────┐         ┌─────────────┐
│     L      │            │      M      │         │      H      │
│ Priority：31│            │ Priority： 32│         │ Priority： 33│
│            │            │             │         │             │
│ hold： LockA│            │ hold： Lock B│         │ hold： NULL  │
│            │            │             │         │             │
│ Wait： NULL │            │ Wait： Lock A│         │ Wait： Lock B│
│            │            │             │         │             │
│ donators：  │            │ donators：   │         │ donators：   │
│            │            │             │         │             │
└────────────┘            └─────────────┘         └─────────────┘

      │                         │                         │
      │                         │                         │
      │                         │                         │
      │                         │                         │
      │                         ▼                         ▼
      ▼
┌──────────────┐         ┌───────────────┐        ┌────────────────┐
│      L       │         │      M        │        │        H       │
│ Priority：32  │         │ Priority： 32  │        │   Priority： 33 │
│              │         │               │        │                │
│ hold：LockA   │         │ hold： Lock B  │        │   hold： NULL   │
│              │         │               │        │                │
│ Wait：NULL    │         │ Wait： Lock A  │        │   Wait： Lock B │
│              │         │               │        │                │
│ donators ：M  │         │ donators：     │        │   donators：    │
└──────────────┘         └───────────────┘        └────────────────┘

     │                         │                         │
     │                         │                         │
     │                         │                         │
     │                         │                         │
     │                         ▼                         ▼
     ▼
  ┌──────────────┐         ┌───────────────┐        ┌────────────────┐
  │      L       │         │      M        │        │        H       │
  │ Priority：33  │         │ Priority： 33  │        │   Priority： 33 │
  │              │         │               │        │                │
  │ hold：LockA   │         │ hold： Lock B  │        │   hold： NULL   │
  │              │         │               │        │                │
  │ Wait：NULL    │         │ Wait： Lock A  │        │   Wait： Lock B │
  │              │         │               │        │                │
  │ donators ：M  │         │ donators：H    │        │   donators：    │
  └──────────────┘         └───────────────┘        └────────────────┘

      │                         │                         │
      │                         │                         │
      │                         │                         │
      │                         │                         │
      │                         ▼                         ▼
      ▼
    ┌──────────────┐         ┌───────────────┐        ┌────────────────┐
    │      L       │         │      M        │        │        H       │
    │ Priority：31  │         │ Priority： 33  │        │   Priority： 33 │
    │              │         │               │        │                │
    │ hold：NULL    │         │ hold： Lock B A│        │   hold： NULL   │
    │              │         │               │        │                │
    │ Wait：NULL    │         │ Wait： NULL    │        │   Wait： Lock B │
    │              │         │               │        │                │
    │ donators ：   │         │ donators：H    │        │   donators：    │
    └──────────────┘         └───────────────┘        └────────────────┘

        │                         │                         │
        │                         │                         │
        │                         │                         │
        │                         │                         │
        │                         ▼                         ▼
        ▼
      ┌──────────────┐         ┌───────────────┐        ┌────────────────┐
      │      L       │         │      M        │        │        H       │
      │ Priority：31  │         │ Priority： 32  │        │   Priority： 33 │
      │              │         │               │        │                │
      │ hold：NULL    │         │ hold： Lock A  │        │   hold： Lock B │
      │              │         │               │        │                │
      │ Wait：NULL    │         │ Wait： NULL    │        │   Wait： NULL   │
      │              │         │               │        │                │
      │ donators ：   │         │ donators：     │        │   donators：    │
      └──────────────┘         └───────────────┘        └────────────────┘




---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

Since I am using semaphore to block a thread,
so when the lock, semaphore, or condition is being release, I use the list_max
to grab the thread with highest priority in the semaphore.waiters list before removing
it from the waiters list. 

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

When lock_acquire is called, the function will first check if the lock is available.
if avaliable, sema_down is called. If not avaliable, start checking if the current_thread's priority
is higher than the one of the thread that is holding the desired lock. If it is higher,
before donating priority to the lock holder, check if there is any thread who also donated
to the lock holder because of the same lock that the current_thread is waiting for.
If there is one, compare the priorities of current_threads and the one already donated, 
if higher, replace it, if not higher, don't do anything. If there is no any thread who also donated
to the lock holder because of the same lock that thread_current is waiting for, directly insert into
the donator list of the lock holder. The nested donation will be handled the same ways as other cases,
because no matter how complicated the donation is, a thread only cares about the one holding its desired 
lock, and my algorithm ensure that if lock holder A is blocked by lock holder B, and thread c is blocked
by lock holder B, the highest priority provided by lock thread c will donate all the way to the lock holder A 
to release it. As a result, lcok will pass to thread c.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for
When the lock_release is called, the thread waiting for the lock will be removed from the 
donators list. And the lock holder will then check if the donators list is emptyor not. If it is
empty, it will reset its priority. If it is not empty, lock holder will set its priority to the priority of the thread with 
highest priority in the lock holder's donators list

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
Yes, because there is case (such as priority_donate_lower), when a thread is donated, it shall not be
able to lower the base priority. But, when mutiple thread is calling thread_set_priority(), it might received a 
unexpected new_priority. In my implementation, since there is only one thread will run at a time because of semaphore
and lock, this problem is avoided.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
This design is easy to debug and does not require less struct or new struct members
than my other design


              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


*** struct thread
{
    ...
    int nice; // value of niceness for each thread.
    fixed_point_t recent_cpu; // value of recent_cpu for each thread.
    ...
}

* nice: integer value of niceness of a thread.
* recent_cpu: the fixed point value of recent_cpu of a thread


---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

## load_avg won't be updated since 36 < TIMER_FREQ, so recent_cpu won't be 
## recalculated except routinely increase 1 for each tick for running_thread.

## Formula: Priority = PRI_MAX - (recent_cpu / 4) - (nice * 2),

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0     0   0   0   63  61  59     A 
 4     4   0   0   62  61  59     A
 8     8   0   0   61  61  59     A (tie but A was newer in the queue)
12    12   0   0   60  61  59     B
16    12   4   0   60  60  59     A (tie but A was newer in the queue)
20    16   4   0   59  60  59     B 
24    16   8   4   59  59  59     B (tie but B was newer in the queue)
28    16  12   4   59  58  59     A (tie but A was newer in the queue)
32    20  12   4   58  58  59     C 
36    20  12   8   58  58  58     C (tie but C was newer in the queue)

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

Answer: Yes, so for C2 the schedule is based on one assumption is that if one of A,B and C can run,
and others are blocked. In the real situation there are more states for threads:
e.g. A is running and B and C are in the ready list. In this case, each tick the recent_cpu increases 1
for all A,B and C because they are in either READY or RUNNING status. This will cause that the rank
of their priority are always same during tick 0-36. If it is an arbitrary algorithm to decide which one of 
A,B and C is running when tie, A can be the one running the whole time, which causes starvation.

To handle this case, with our implementation which is a flatten priority list, we might want to list_insert_ordered
but to the back of the list so that forms a FILO(first in last out) data structure, and threads with the same
priority using round-robin aloghrithm can more avarge running time.

No, acutally we haven't met this problem yet, its now just a theoretical case, but under our data structure it 
might happens.


>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

So bascially, we only want to keep minimum functionality inside each interrupt to guarantee that the 
interrupt and timer_tick will not be slowed down due to overhead. So, we only make functions which requires interrupts to switch
between threads inside the interrupt (e.g. for wake up sleeping threads, it has to be called by an interrupt.)

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Answer: I would say our code is made of abstruction making wrappers for each individual functionality, which makes code more
readable and understandable, but the corresponding disadvantage is that function calls actually increase the overhead
like passing and returning variables, memory allocation, and storing symbols. In OS, efficiency is important and some high-level
language implementation might potential harm the efficiency. 

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

Answer: It is provided by Professor.

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?